{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.compose import make_column_transformer,make_column_selector\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet,Ridge\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.feature_selection import RFE\n",
    "from prettytable import PrettyTable\n",
    "from prettytable import PrettyTable\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import  cross_validate\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/Lynda/Desktop/anticipez les besoins en consommation de batiment/data_filtre.csv')\n",
    "data = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des valeurs manquantes par la moyenne\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "#data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(data['SiteEnergyUse(kBtu)'])\n",
    "X = data.drop(columns=['TotalGHGEmissions','SiteEnergyUse(kBtu)'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' X_train: {X_train.shape} \\n X_test :  {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_learning_curve(\n",
    "    estimator,title,X,y,axes=None,ylim=None,cv=None,n_jobs=None,train_sizes=np.linspace(0.1, 1.0, 5),scoring = None):\n",
    "    \n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    if scoring != None :\n",
    "        axes[0].set_ylabel(\"Score - \" + str(scoring))\n",
    "    else :\n",
    "        axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = learning_curve(\n",
    "        estimator,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes,\n",
    "        return_times=True,\n",
    "        scoring = scoring\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    #plt.grid()\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        train_scores_mean - train_scores_std,\n",
    "        train_scores_mean + train_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"r\",\n",
    "    )\n",
    "    axes[0].fill_between(\n",
    "        train_sizes,\n",
    "        test_scores_mean - test_scores_std,\n",
    "        test_scores_mean + test_scores_std,\n",
    "        alpha=0.1,\n",
    "        color=\"g\",\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, train_scores_mean, \"o-\", color=\"r\", label=\"Training score\"\n",
    "    )\n",
    "    axes[0].plot(\n",
    "        train_sizes, test_scores_mean, \"o-\", color=\"g\", label=\"Cross-validation score\"\n",
    "    )\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, \"o-\")\n",
    "    axes[1].fill_between(\n",
    "        train_sizes,\n",
    "        fit_times_mean - fit_times_std,\n",
    "        fit_times_mean + fit_times_std,\n",
    "        alpha=0.1,\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "\n",
    "\n",
    "\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cross_val_score(models, X, y, cv=5, scoring='r2'):\n",
    "    t = PrettyTable([\"Model\",'Score', \"std_acc (+/-)\", 'Time'], reversesort = True)\n",
    "    min_score = 0\n",
    "    best_model = ''\n",
    "    for reg in models: \n",
    "        st = time.time()\n",
    "        scores = cross_val_score(reg[1], X, y, scoring =scoring , cv=cv, n_jobs = -1)\n",
    "        # scoring : ' explained_variance_score', ' neg_mean_squared_error', 'r2', 'neg_mean_squared_error'\n",
    "        t.add_row([reg[0],round(scores.mean(),4), round(scores.std(),4), round(time.time() - st,4)])\n",
    "        if min_score < scores.mean():\n",
    "            best_model = reg[1]\n",
    "            name=reg[0]\n",
    "            min_score = scores.mean()\n",
    "    print (t)\n",
    "    return (best_model,name,min_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feautures = make_column_selector(dtype_include = np.number)\n",
    "categorical_features = make_column_selector(dtype_exclude= np.number)\n",
    "numerical_pipeline = make_pipeline(StandardScaler())\n",
    "categorical_pipeline = make_pipeline(OneHotEncoder(handle_unknown = \"ignore\"))\n",
    "\n",
    "preprocessor = make_column_transformer((numerical_pipeline,numerical_feautures),\n",
    "                                        (categorical_pipeline,categorical_features))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridg   = make_pipeline(preprocessor,Ridge())\n",
    "linearregression = make_pipeline(preprocessor,LinearRegression())\n",
    "elasticnet = make_pipeline(preprocessor ,  ElasticNet())\n",
    "gradientboosting = make_pipeline(preprocessor, GradientBoostingRegressor())\n",
    "randomforest = make_pipeline(preprocessor,RandomForestRegressor())  \n",
    "svr  = make_pipeline(preprocessor,SVR())\n",
    "xgboost = make_pipeline(preprocessor,xgb.XGBRegressor()) \n",
    "\n",
    "dict_of_models = { 'ridg': Ridg,\n",
    "                    'linearregression':linearregression ,\n",
    "                    'elasticnet': elasticnet,\n",
    "                    'xgboost':xgboost,\n",
    "                    'gradientboosting':gradientboosting,\n",
    "                    'randomforest':randomforest,\n",
    "                    'svr':svr ,\n",
    "                    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridg.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridg_grid = { \n",
    "    'ridge__fit_intercept':[True,False],\n",
    "    'ridge__alpha':np.logspace(-4,6,20)\n",
    "}\n",
    "\n",
    "linear_grid = {\n",
    "'linearregression__fit_intercept':[True,False]\n",
    "#'linearregression__normalize':[True,False]\n",
    "}\n",
    "\n",
    "elasticnet_grid = {\n",
    "    \"elasticnet__tol\" : [0.1,0.01,0.001,0.0001],\n",
    "    \"elasticnet__alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],  #alpha, coef qui multiplie le terme de pénalité)\n",
    "    \"elasticnet__l1_ratio\": np.arange(-1.0, 1.0, 0.2),\n",
    "    'elasticnet__fit_intercept':[True,False]  \n",
    "}\n",
    "\n",
    "gb_grid = {\n",
    "    'gradientboostingregressor__learning_rate':[0.001, 0.01, 0.1, 0.2, 0, 3],\n",
    "    'gradientboostingregressor__max_depth' : [1, 6, 12, 20]\n",
    "}\n",
    "\n",
    "randomforest_grid = {\n",
    "    'randomforestregressor__n_estimators' : [700, 900],\n",
    "    #'randomforestregressor__max_depth': [1000,1400,1600 ],\n",
    "   # 'randomforestregressor__min_samples_split': [10, 20], \n",
    "    'randomforestregressor__max_features': [4,10,30]\n",
    "}\n",
    "\n",
    "svr_grid = {\n",
    "    'svr__gamma':[0.001, 0.01, 1],\n",
    "    'svr__epsilon':[0, 0.01, 0.1, 0.5, 1],\n",
    "    'svr__C':np.logspace(5, 0, 10)\n",
    "}\n",
    "\n",
    "xgboost_grid = {\n",
    "    'xgbregressor__learning_rate': np.logspace(-2,0,10),\n",
    "    'xgbregressor__gamma':[0, 0.25, 0.5, 1.0],\n",
    "    # 'xgbregressor__max_depth':[1, 4, 10, 20],\n",
    "    'xgbregressor__n_estimators':[50, 150, 200]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_searchridge= GridSearchCV(Ridg , param_grid = ridg_grid  , n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchrelasticnet= GridSearchCV(elasticnet , param_grid = elasticnet_grid, n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchlinear= GridSearchCV(linearregression , param_grid = linear_grid , n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchxgboost= GridSearchCV(xgboost , param_grid = xgboost_grid, n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchrandomforest= GridSearchCV(randomforest , param_grid = randomforest_grid, n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchsvr= GridSearchCV(svr , param_grid = svr_grid, n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n",
    "grid_searchgbt= GridSearchCV(gradientboosting , param_grid = gb_grid, n_jobs = -1, cv =5,scoring = 'r2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def evaluate(grid, X_train,y_train,X_test,y_test,name):\n",
    "    \n",
    "        score = 'explained_variance'\n",
    "        start_time = time.time()\n",
    "        result = grid.fit(X_train,y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        print(\"=\"*30)\n",
    "        print(name)\n",
    "        print('\\nBest Score to optimize: '+score+' = %s' % result.best_score_)\n",
    "        print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "        print('\\n****Results****')\n",
    "        predictions = result.predict(X_test)\n",
    "\n",
    "        explained_variance = result.best_score_\n",
    "        r2 = sklearn.metrics.r2_score(y_test, predictions)\n",
    "\n",
    "        #print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "        #print(\"Mean Absolute Error: {}\".format(mae))\n",
    "        print(\"Explained Variance: {}\".format(explained_variance))\n",
    "        print(\"R2 Score: {}\".format(r2))\n",
    "        print(\"Training time: {}s\".format(round(training_time, 2)))\n",
    "        \n",
    "        # features_names = result.feature_names_in_\n",
    "        # #print(features_names)\n",
    "        # features_importance = grid.best_estimator_[1].feature_importances_\n",
    "        # order_importance = np.argsort(grid.best_estimator_[1].feature_importances_)[::-1]\n",
    "        #print(order_importance)\n",
    "\n",
    "        # GRAPHS\n",
    "        fig = plt.figure(figsize=(8, 5))\n",
    "        \n",
    "        # plot valeurs réelles / valeurs prédites\n",
    "        X_plot = [y_test.min(), y_test.max()]\n",
    "        #plt.subplot(1,2,1)\n",
    "        plt.scatter(y_test, predictions, alpha=.6)\n",
    "        plt.plot(X_plot, X_plot, color='r')\n",
    "        plt.title(\"Valeurs prédites VS valeurs réelles\")\n",
    "        plt.xlabel(\"Valeurs réelles\")\n",
    "        plt.ylabel(\"Valeurs prédites\")\n",
    "\n",
    "        # # Features importance\n",
    "\n",
    "        if grid in [grid_searchrandomforest,grid_searchgbt,grid_searchxgboost]:\n",
    "                feat = list(zip(result.feature_names_in_, grid.best_estimator_[1].feature_importances_))\n",
    "                df_importances = pd.DataFrame(feat, columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "                df_importances.plot.barh(x='Feature', y='Importance')\n",
    "\n",
    "          \n",
    "        \n",
    "        if grid in [grid_searchlinear,grid_searchridge,grid_searchrelasticnet, grid_searchsvr ]:\n",
    "\n",
    "                features = X_train.columns\n",
    "                feature_names = features.tolist()\n",
    "                model = result.best_estimator_\n",
    "                feature_importance = np.abs(model.steps[-1][1].coef_)\n",
    "                pos = np.argsort(feature_importance)\n",
    "                #print(feature_importance)\n",
    "                reg_feat_importance = pd.DataFrame(columns=[\"Feature Name\", \"Feature Importance\"])\n",
    "                feat = list(zip(result.feature_names_in_, pos))\n",
    "                df_importances = pd.DataFrame(feat, columns=['Feature', 'Importance']).sort_values(by='Importance', ascending=False)\n",
    "                df_importances.plot.barh(x='Feature', y='Importance')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #feature_importance = clf.feature_importances_\n",
    "# #grid_searchrandomforest.feature_names\n",
    "# clf.feature_names_\n",
    "\n",
    "# features_names = clf.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles lineaires:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régression_linear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchlinear,X_train,y_train,X_test,y_test,'Model_LinearRegressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Linear_regression'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(linearregression, title, X, y, axes=axes, cv=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchridge,X_train,y_train,X_test,y_test,'Model_Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Modele_Ridge'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(Ridg, title, X, y, axes=axes, cv=5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchrelasticnet,X_train,y_train,X_test,y_test,'Model_ElasticNet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Modele_Elasticnet'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(elasticnet, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchsvr,X_train,y_train,X_test,y_test,'svr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'svr'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(svr, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomforestregressor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchrandomforest,X_train,y_train,X_test,y_test,'RandomForestRogressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'RandomForestRegressor'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(randomforest, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gradient bossting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchgbt,X_train,y_train,X_test,y_test,'Gradientboosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Gradient boosting'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(gradientboosting, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchxgboost,X_train,y_train,X_test,y_test,'xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'xgboost'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(xgboost, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection du meilleur modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X,y):\n",
    "    models = [#('Ridg', grid_searchridge.fit(X,y)),\n",
    "\n",
    "           # ('elasticnet', grid_searchridge.fit(X,y)),\n",
    "\n",
    "           # ('linearregression' , grid_searchlinear.fit(X,y)),\n",
    "\n",
    "             ('xgboost', grid_searchxgboost.fit(X,y)),\n",
    "\n",
    "            #('svr', grid_searchsvr.fit(X,y).best_estimator_),\n",
    "\n",
    "             ('randomforest' , grid_searchrandomforest.fit(X,y).best_estimator_),\n",
    "             \n",
    "            ('gradientboosting' ,grid_searchgbt.fit(X,y).best_estimator_)\n",
    "    ]\n",
    "\n",
    "\n",
    "    best_model = model_cross_val_score(models,X,y,cv = 5)\n",
    "    return best_model\n",
    "  \n",
    "best_model_1=run_model(X_train, y_train)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sur les 4 modèles testés, les modèles linéaires retournent de moins bonnes métriques en général. Si nous prenons en considération le score Explained Variance, qui aura du sens sur les modèles linéaires et non-linéaires, l'algorithme xgboost offrent les meilleures performances la qualité des prédictions mais le temps de calcul est relativement plus long, randomforestregressor egalement offre de meilleurs performance meme en terme de temps.\n",
    "\n",
    "On observe également que le passage au log améliore significativement les résultats des modèles non-linéaires. En effet, cela se justifie par certaines features étant très déviée proche de 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modélisation sans la variable ENERGYSTARScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(data['SiteEnergyUse(kBtu)'])\n",
    "X = data.drop(columns=['TotalGHGEmissions','SiteEnergyUse(kBtu)','ENERGYSTARScore'], axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "print(f' X_train: {X_train.shape} \\n X_test :  {X_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation avec le modele RandomForest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchrandomforest,X_train,y_train,X_test,y_test,'RandomForestRogressor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'RandomForestRegressor'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(randomforest, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  évaluation avec le modèle xgboost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchxgboost,X_train,y_train,X_test,y_test,'Xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'xgboost'\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 4))\n",
    "plot_learning_curve(xgboost, title, X, y, axes=axes, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(grid_searchgbt,X_train,y_train,X_test,y_test,'Gradientboosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(X,y):\n",
    "    models = [\n",
    "\n",
    "           \n",
    "\n",
    "             ('xgboost', grid_searchxgboost.fit(X,y)),\n",
    "\n",
    "             ('randomforest' , grid_searchrandomforest.fit(X,y).best_estimator_),\n",
    "             \n",
    "            ('gradientboosting' ,grid_searchgbt.fit(X,y).best_estimator_)\n",
    "    ]\n",
    "\n",
    "\n",
    "    best_model = model_cross_val_score(models,X,y,cv = 5)\n",
    "    return best_model\n",
    "  \n",
    "best_model_1=run_model(X_train, y_train)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des données prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def predict(grid, X_train,y_train,X_test,y_test):\n",
    "    \n",
    "        score = 'explained_variance'\n",
    "        start_time = time.time()\n",
    "        result = grid.fit(X_train,y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        print(\"=\"*30)\n",
    "        \n",
    "        print('\\nBest Score to optimize: '+score+' = %s' % result.best_score_)\n",
    "        print('Best Hyperparameters: %s' % result.best_params_)\n",
    "\n",
    "        print('\\n****Results****')\n",
    "        predictions = result.predict(X_test)\n",
    "\n",
    "        explained_variance = result.best_score_\n",
    "        r2 = sklearn.metrics.r2_score(y_test, predictions)\n",
    "\n",
    "        #print(\"Root Mean Squared Error: {}\".format(rmse))\n",
    "        #print(\"Mean Absolute Error: {}\".format(mae))\n",
    "        print(\"Explained Variance: {}\".format(explained_variance))\n",
    "        print(\"R2 Score: {}\".format(r2))\n",
    "        print(\"Training time: {}s\".format(round(training_time, 2)))\n",
    "        \n",
    "        return np.exp(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict(grid_searchgbt, X_train.drop('ENERGYSTARScore', axis=1)\n",
    "                       , y_train, X_test.drop('ENERGYSTARScore', axis=1)\n",
    "                       , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('database')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6df166256a7b547fa959d064b4897237e544bb355e7a9129d50183241b40e5b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
